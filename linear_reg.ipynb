{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (one large matrix?)\n",
    "datafiles = ['../project/dataset1.csv', '../project/dataset2.csv', '../project/dataset3.csv', '../project/dataset4.csv', '../project/dataset5.csv']\n",
    "n_samples = 50000           # Number of samples\n",
    "n_dataset = len(datafiles)  # Number of datasets\n",
    "train = 0.9   # 245000 (77.777...%)\n",
    "test = 0.1    # 35000 (10%)\n",
    "# val = 1-train # 70000 (Rest)\n",
    "\n",
    "size_test = int(n_samples*n_dataset*test)+1\n",
    "size_train = int((n_samples*n_dataset-size_test)*train)+1\n",
    "# size_val = int((n_samples*n_dataset-size_test)*val)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 5)\n",
      "0.195132062642601\n",
      "Number of entangled states: 127330\n",
      "\n",
      "Number of separable states: 122670\n",
      "\n",
      "(225000, 4)\n",
      "(25000, 4)\n",
      "(225000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Split all datasets\n",
    "datasets = np.empty((int(n_samples*n_dataset),5))\n",
    "print(datasets.shape)\n",
    "for i,datafile in enumerate(datafiles):\n",
    "  dataset = np.loadtxt(datafile, delimiter=',')\n",
    "  datasets[int(i*n_samples):int(n_samples*(i+1)),:] = dataset\n",
    "print(datasets[0,0])\n",
    "# Split into input and output\n",
    "Cr = datasets[:,0:4]   # Input: relative entropy of coherence\n",
    "ES = np.array([float(y) for y in datasets[:,4]])  # Output: entangled/separable\n",
    "\n",
    "# Count number of entangled and separable states\n",
    "n_entangled = len([es for es in ES if es == 1])\n",
    "print(f'Number of entangled states: {n_entangled}\\n')\n",
    "print(f'Number of separable states: {n_samples*n_dataset-n_entangled}\\n')\n",
    "# Split into train-and-validation and test\n",
    "#break datasets into train and test\n",
    "\n",
    "Cr_train, Cr_test, ES_train, ES_test = train_test_split(Cr, ES, test_size=test,\n",
    "                                                      random_state=42)\n",
    "# # Split into train and validation\n",
    "# Cr_train, Cr_val, ES_train, ES_val = train_test_split(Cr_trainval, ES_trainval, test_size=val,\n",
    "#                                                       random_state=30)\n",
    "# DEBUG\n",
    "print(np.shape(Cr_train))\n",
    "print(np.shape(Cr_test))\n",
    "print(np.shape(ES_train))\n",
    "print(np.shape(ES_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tansform data into tensors\n",
    "Cr_tensor = torch.tensor(Cr, dtype=torch.float32)\n",
    "ES_tensor = torch.tensor(ES, dtype=torch.float32)\n",
    "# Cr_train = torch.tensor(Cr_train, dtype=torch.float32)\n",
    "# Cr_test = torch.tensor(Cr_test, dtype=torch.float32)\n",
    "# ES_train = torch.tensor(ES_train, dtype=torch.float32)\n",
    "# ES_test = torch.tensor(ES_test, dtype=torch.float32)\n",
    "\n",
    "# # In case we have a gpu\n",
    "Cr_tensor = Cr_tensor.to(device)\n",
    "ES_tensor = ES_tensor.to(device)\n",
    "# Cr_train = Cr_train.to(device)\n",
    "# Cr_test = Cr_test.to(device)\n",
    "# ES_train = ES_train.to(device)\n",
    "# ES_test = ES_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "tensor_dataset = TensorDataset(Cr_tensor, ES_tensor)\n",
    "dataset = DataLoader(tensor_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class NeuralNetwork_3layer_with_a0(nn.Module):\n",
    "    def __init__(self, n_nodes):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(4, n_nodes)\n",
    "        self.layer2 = nn.Linear(n_nodes,5)\n",
    "        self.layer3 = nn.Linear(5, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "      # if input x provided, describe how to produce output tensor\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.sig(self.layer2(x))\n",
    "        x = self.sig(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "    def _init_weights(self, l):\n",
    "      # Initialize weights uniformly\n",
    "      if isinstance(l, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(l.weight)\n",
    "        #nn.init.uniform_(l.weight)\n",
    "        l.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        y = y.view(-1, 1)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_model(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # Reshape y to match pred's shape\n",
    "            y = y.view(-1, 1)  # Assuming y has shape (batch_size, 1)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.round() == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.308821 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.288281 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.269343 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.232246 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.196962 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.170735 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.153375 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.143128 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.139010 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.128896 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.131289 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.125108 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.120297 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.125079 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.119907 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.110739 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.113930 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.108253 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.107173 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.104883 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.104534 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.103745 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.099306 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.098652 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.107705 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.097248 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.099145 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [78], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     test_model(dataset, model, loss_fn)\n",
      "Cell \u001b[0;32mIn [77], line 13\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 13\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     15\u001b[0m     loss, current \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem(), batch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/optim/rmsprop.py:150\u001b[0m, in \u001b[0;36mRMSprop.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`step` can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt be a tensor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    147\u001b[0m         state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 150\u001b[0m     \u001b[43mrmsprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[43msquare_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrad_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcentered\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/optim/rmsprop.py:201\u001b[0m, in \u001b[0;36mrmsprop\u001b[0;34m(params, grads, square_avgs, grad_avgs, momentum_buffer_list, foreach, maximize, differentiable, lr, alpha, eps, weight_decay, momentum, centered)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_rmsprop\n\u001b[0;32m--> 201\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m     \u001b[49m\u001b[43msquare_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m     \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcentered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/optim/rmsprop.py:259\u001b[0m, in \u001b[0;36m_single_tensor_rmsprop\u001b[0;34m(params, grads, square_avgs, grad_avgs, momentum_buffer_list, lr, alpha, eps, weight_decay, momentum, centered, maximize, differentiable)\u001b[0m\n\u001b[1;32m    257\u001b[0m     avg \u001b[38;5;241m=\u001b[39m avg\u001b[38;5;241m.\u001b[39madd(eps)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[43mavg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m momentum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    262\u001b[0m     buf \u001b[38;5;241m=\u001b[39m momentum_buffer_list[i]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork_3layer_with_a0(50).to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_model(dataset, model, loss_fn, optimizer)\n",
    "    test_model(dataset, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Module.parameters() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [71], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Define optimizer - RMSprop optimizer with default hyperparameters\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mRMSprop(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\u001b[38;5;66;03m#,alpha=0.99,eps=1e-7)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Definition to extract P_i-values\u001b[39;00m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mlayer2\u001b[38;5;241m.\u001b[39mregister_forward_hook(get_activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Module.parameters() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "# Train model without inequality\n",
    "model = LinearRegressionWithHidden   # Define model you want to train\n",
    "epochs = 50        # Number of epochs\n",
    "batches = 32       # Batch size\n",
    "\n",
    "start = 100      # Limit for early stopping\n",
    "stop_th = 50     # Early stopping threshold\n",
    "\n",
    "best_acc = -1   # Save best accuracy\n",
    "best_e = -1     # Save best epoch\n",
    "losses = []     # Save epoch losses\n",
    "accs_val = []  # Save validation accuracy\n",
    "accs_train = [] # Save train accuracy\n",
    "count = 1       # Count for lower limit for early stopping\n",
    "\n",
    "# Define Loss function - binary cross-entropy\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Define optimizer - RMSprop optimizer with default hyperparameters\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)#,alpha=0.99,eps=1e-7)\n",
    "\n",
    "# Definition to extract P_i-values\n",
    "model.layer2.register_forward_hook(get_activation('layer2'))\n",
    "\n",
    "for e in range(epochs):\n",
    "    # Training the model on training data set\n",
    "    model.train()   # Model put into training mode\n",
    "    for b in range(0, len(Cr_train), batches):\n",
    "      ES_pred = model(Cr_train[b:b+batches,:])   # Train\n",
    "      loss = loss_fn(ES_pred, ES_train[b:b+batches,:]) # Calculate loss\n",
    "      optimizer.zero_grad()   # Resets gradients\n",
    "      loss.backward()         # Calculate gradients\n",
    "      optimizer.step()        # Update weights\n",
    "\n",
    "    # Evaluation on training and validation data set\n",
    "    model.eval()            # Evaluation\n",
    "    ES_pred_val = model(Cr_test)       # Evaluation validation data\n",
    "    alphas_val = torch.sigmoid(activation['layer2'])\n",
    "    ES_pred_train = model(Cr_train_norm)   # Evaluation train data\n",
    "    alphas_train = torch.sigmoid(activation['layer2'])\n",
    "    #print(alphas_val)\n",
    "    #print(alphas_train)\n",
    "\n",
    "    # Evaluating inequality\n",
    "    ES_ineq_train = ineq(alphas_train, Cr_train)\n",
    "    ES_ineq_val = ineq(alphas_val, Cr_val)\n",
    "    acc_ineq_train = (ES_ineq_train == ES_train).float().mean()\n",
    "    acc_ineq_val = (ES_ineq_val == ES_val).float().mean()\n",
    "    TS, FE, FS, TE = confusion_matrix(ES_train.cpu().detach().numpy(), ES_ineq_train.cpu().detach().numpy()).ravel()\n",
    "    print(f'For epoch {e}, inequality accuracy = {acc_ineq_train*100}%\\n')\n",
    "    print(f'TS: {TS} FE: {FE} FS: {FS} TE: {TE}\\n')\n",
    "    #print(f'Alphas: {alphas[1:10]}\\n')\n",
    "\n",
    "    # Calculate and save loss\n",
    "    loss = loss_fn(ES_pred_train, ES_train)\n",
    "    losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    # Calculating and saving accuracies\n",
    "    acc_val = (ES_pred_val.round() == ES_val).float().mean()   # Accuracy validation set\n",
    "    acc_train = (ES_pred_train.round() == ES_train).float().mean()   # Accuracy train set\n",
    "    accs_val.append(acc_val.cpu().detach().numpy())   # For plotting\n",
    "    accs_train.append(acc_train.cpu().detach().numpy())   # For plotting\n",
    "    print(f'For epoch {e}, validation accuracy = {acc_val*100}%\\n')\n",
    "\n",
    "    # Printing!\n",
    "    print(f'Epoch {e}!\\n')\n",
    "    print(f'Loss: {loss}')\n",
    "\n",
    "\n",
    "    # Checkpointing and early stopping\n",
    "    if acc_val > best_acc:\n",
    "        best_acc = acc_val\n",
    "        best_e = e\n",
    "        checkpoint(model, 'best_model.pth')\n",
    "    elif (count > start) and (e - best_e > stop_th):\n",
    "        print(f'Early stop at epoch = {e}\\n')\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "resume(model, 'best_model.pth')   # Use best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200000, 4]), torch.Size([200000]), (200000, 4), numpy.ndarray)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cr_trainval_tensor.shape, ES_trainval_tensor.shape, Cr_trainval.shape, type(Cr_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [85], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#merge the data Cr_trainval_tensor ES_trainval_tensor\u001b[39;00m\n\u001b[1;32m     16\u001b[0m Cr_trainval \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTensorDataset(Cr_trainval_tensor, ES_trainval_tensor)\n\u001b[0;32m---> 17\u001b[0m Cr_test \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCr_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mES_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(Cr_trainval, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(Cr_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/utils/data/dataset.py:189\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/utils/data/dataset.py:189\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "model = LinearRegressionWithHidden()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Split data into train and test sets\n",
    "Cr_trainval, Cr_test, ES_trainval, ES_test = train_test_split(Cr, ES, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "# Cr = X Es = Y\n",
    "Cr_trainval_tensor = torch.tensor(Cr_trainval, dtype=torch.float32)\n",
    "ES_trainval_tensor = torch.tensor(ES_trainval, dtype=torch.float32)\n",
    "#merge the data Cr_trainval_tensor ES_trainval_tensor\n",
    "Cr_trainval = torch.utils.data.TensorDataset(Cr_trainval_tensor, ES_trainval_tensor)\n",
    "Cr_test = torch.utils.data.TensorDataset(Cr_test,ES_test)\n",
    "train_loader = DataLoader(Cr_trainval, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(Cr_test, batch_size=10, shuffle=True)\n",
    "\n",
    "\n",
    "# Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4])\n",
      "tensor([[2.8292e-01, 5.0141e-01, 2.8292e-01, 1.0699e-03],\n",
      "        [6.0408e-01, 6.5331e-01, 6.3826e-01, 5.8904e-01],\n",
      "        [7.4930e-02, 3.8622e-02, 4.4818e-02, 7.8443e-02],\n",
      "        [7.4905e-02, 6.5564e-02, 3.4092e-02, 6.6149e-02],\n",
      "        [9.3140e-02, 1.4367e-01, 9.3140e-02, 7.2529e-03],\n",
      "        [2.3706e-01, 2.3727e-01, 2.3706e-01, 1.3707e-01],\n",
      "        [1.1822e+00, 1.0417e+00, 1.1822e+00, 5.9894e-01],\n",
      "        [4.1536e-01, 5.8036e-01, 3.6490e-01, 1.9990e-01],\n",
      "        [6.6071e-02, 6.0675e-02, 6.6071e-02, 4.0399e-02],\n",
      "        [3.3015e-01, 3.4334e-01, 3.5657e-01, 3.4338e-01]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    print(x.shape)\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(Cr_trainval_tensor)\n",
    "    ES_trainval_tensor = ES_trainval_tensor.view(-1, 1)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, ES_trainval_tensor)\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# After training, you can evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    Cr_test_tensor = torch.tensor(Cr_test, dtype=torch.float32)\n",
    "    ES_test_tensor = torch.tensor(ES_test, dtype=torch.float32)\n",
    "\n",
    "    # Forward pass through the model to get predictions\n",
    "    outputs = model(Cr_test_tensor)\n",
    "\n",
    "    # Convert the output tensor to have the same shape as the target tensor\n",
    "    outputs = outputs.view(-1)  # Ensure the output tensor is 1D\n",
    "\n",
    "    # Calculate the test loss\n",
    "    test_loss = criterion(outputs, ES_test_tensor)\n",
    "\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
