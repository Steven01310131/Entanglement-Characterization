{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (one large matrix?)\n",
    "datafiles = ['../project/dataset1.csv', '../project/dataset2.csv', '../project/dataset3.csv', '../project/dataset4.csv', '../project/dataset5.csv']\n",
    "n_samples = 50000           # Number of samples\n",
    "n_dataset = len(datafiles)  # Number of datasets\n",
    "train = 0.9   # 245000 (77.777...%)\n",
    "test = 0.1    # 35000 (10%)\n",
    "# val = 1-train # 70000 (Rest)\n",
    "\n",
    "size_test = int(n_samples*n_dataset*test)+1\n",
    "size_train = int((n_samples*n_dataset-size_test)*train)+1\n",
    "# size_val = int((n_samples*n_dataset-size_test)*val)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 5)\n",
      "0.195132062642601\n",
      "Number of entangled states: 127330\n",
      "\n",
      "Number of separable states: 122670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split all datasets\n",
    "datasets = np.empty((int(n_samples*n_dataset),5))\n",
    "print(datasets.shape)\n",
    "for i,datafile in enumerate(datafiles):\n",
    "  dataset = np.loadtxt(datafile, delimiter=',')\n",
    "  datasets[int(i*n_samples):int(n_samples*(i+1)),:] = dataset\n",
    "print(datasets[0,0])\n",
    "# Split into input and output\n",
    "Cr = datasets[:,0:4]   # Input: relative entropy of coherence\n",
    "ES = np.array([float(y) for y in datasets[:,4]])  # Output: entangled/separable\n",
    "\n",
    "# Count number of entangled and separable states\n",
    "n_entangled = len([es for es in ES if es == 1])\n",
    "print(f'Number of entangled states: {n_entangled}\\n')\n",
    "print(f'Number of separable states: {n_samples*n_dataset-n_entangled}\\n')\n",
    "# Split into train-and-validation and test\n",
    "Cr_trainval, Cr_test, ES_trainval, ES_test = train_test_split(Cr, ES, test_size=test,\n",
    "                                                      random_state=42)\n",
    "# # Split into train and validation\n",
    "# Cr_train, Cr_val, ES_train, ES_val = train_test_split(Cr_trainval, ES_trainval, test_size=val,\n",
    "#                                                       random_state=30)\n",
    "# DEBUG\n",
    "# print(np.shape(Cr_train))\n",
    "# print(np.shape(Cr_test))\n",
    "# print(np.shape(Cr_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class LinearRegressionWithHidden(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionWithHidden, self).__init__()\n",
    "        self.layer1= nn.Linear(4, 5)\n",
    "        self.layer2= nn.Linear(5, 1)\n",
    "        self.output= nn.Linear(1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        output = self.sigmoid(self.output(x))\n",
    "        output = torch.where(output <= 4, torch.tensor(0.0), torch.tensor(1.0))\n",
    "        output.requires_grad = True\n",
    "        return output\n",
    "\n",
    "    def _init_weights(self, l):\n",
    "      # Initialize weights uniformly\n",
    "      if isinstance(l, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(l.weight)\n",
    "        #nn.init.uniform_(l.weight)\n",
    "        l.bias.data.fill_(0.01)\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = LinearRegressionWithHidden()\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# # Convert numpy arrays to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(Cr_train, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(ES_train, dtype=torch.float32)\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs =\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(X_train_tensor)\n",
    "#     loss = criterion(outputs, y_train_tensor)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if (epoch+1) % 10 == 0:\n",
    "#         print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# # Evaluate the model\n",
    "# with torch.no_grad():\n",
    "#     predicted = model(X_train_tensor).detach().numpy()\n",
    "#     print(\"Training Loss:\", criterion(torch.tensor(predicted), y_train_tensor).item())\n",
    "\n",
    "# # Get the learned parameters\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.5090\n",
      "Epoch [20/100], Loss: 0.5090\n",
      "Epoch [30/100], Loss: 0.5090\n",
      "Epoch [40/100], Loss: 0.5090\n",
      "Epoch [50/100], Loss: 0.5090\n",
      "Epoch [60/100], Loss: 0.5090\n",
      "Epoch [70/100], Loss: 0.5090\n",
      "Epoch [80/100], Loss: 0.5090\n",
      "Epoch [90/100], Loss: 0.5090\n",
      "Epoch [100/100], Loss: 0.5090\n",
      "Test Loss: 0.5106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LinearRegressionWithHidden()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Split data into train and test sets\n",
    "Cr_trainval, Cr_test, ES_trainval, ES_test = train_test_split(Cr, ES, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "Cr_trainval_tensor = torch.tensor(Cr_trainval, dtype=torch.float32)\n",
    "ES_trainval_tensor = torch.tensor(ES_trainval, dtype=torch.float32)\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(Cr_trainval_tensor)\n",
    "    ES_trainval_tensor = ES_trainval_tensor.view(-1, 1)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, ES_trainval_tensor)\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# After training, you can evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    Cr_test_tensor = torch.tensor(Cr_test, dtype=torch.float32)\n",
    "    ES_test_tensor = torch.tensor(ES_test, dtype=torch.float32)\n",
    "\n",
    "    # Forward pass through the model to get predictions\n",
    "    outputs = model(Cr_test_tensor)\n",
    "\n",
    "    # Convert the output tensor to have the same shape as the target tensor\n",
    "    outputs = outputs.view(-1)  # Ensure the output tensor is 1D\n",
    "\n",
    "    # Calculate the test loss\n",
    "    test_loss = criterion(outputs, ES_test_tensor)\n",
    "\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
